# Project Overview
This project was completed as part of my PGP in AI & ML from Great Learning. It focuses on implementing various ensemble learning techniques to enhance model accuracy and robustness. The project explores methods like Bagging, Boosting, and Random Forest to build high-performing predictive models.

# Key Objectives
  * Perform Exploratory Data Analysis (EDA) to understand the dataset.
  * Preprocess data, handle missing values, and apply feature engineering.
  * Implement and compare Ensemble Learning models:
     - Bagging (Random Forest, Bagging Classifier)
     - Boosting (AdaBoost, Gradient Boosting)
     - Stacking (Combining multiple base models)
  * Optimize models using hyperparameter tuning.
  * Compare model performances and derive key insights.

# Tools & Libraries Used
  * Python (Jupyter Notebook)
  * Scikit-Learn (Machine Learning Models)
  * Boosting Techniques
  * Pandas, NumPy (Data Manipulation)
  * Matplotlib, Seaborn (Data Visualization)
  * Hyperparameter Tuning (GridSearchCV, RandomizedSearchCV)

# Analysis Performed
  * Data Preprocessing (Handling missing values, encoding, scaling)
  * Feature Engineering & Selection
  * Ensemble Model Training & Evaluation
  * Hyperparameter Tuning (GridSearchCV, RandomizedSearchCV)
  * Comparison of Model Performance

***
***
**Author:** Prinkle Nanda
<br>**Contact:** prinklenanda4@gmail.com 
<br>*If you find this project useful, feel free to ‚≠ê star the repo!*
